# Conseils de robustesse JSON

	â€¢	Toujours parse-server â†’ si Ã©chec, retenter avec message systÃ¨me: â€œTa derniÃ¨re sortie nâ€™Ã©tait PAS un JSON valide. Renvoie UNIQUEMENT un JSON valide sans commentaire.â€
	â€¢	Limiter la taille des batchs (â‰¤ ~2k tokens) en live.
	â€¢	Normaliser les dates avec regex cÃ´tÃ© serveur si Claude renvoie du â€œ25/10â€ â†’ transformer en â€œYYYY-MM-DDâ€ quand possible.


---

## ğŸ—ï¸ ARCHITECTURE_DIAGRAMME.md

```markdown
# Architecture â€” Meeting Copilot (POC realtime + post)

## 0) Vue dâ€™ensemble (ASCII)
Client (Next.js) â”€â”€WebRTCâ”€â”€â–¶ OpenAI Realtime
     â”‚                               â”‚
     â”‚ (WS/polling /api/suggestions) â”‚
     â–¼                               â”‚
Next.js API (Node) â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â–¶ /api/suggestions  (Claude Sonnet: micro-batch â†’ JSON LIVE)
     â”œâ”€â–¶ /api/summary      (Claude Sonnet: post-meeting â†’ JSON FINAL)
     â””â”€â–¶ Storage volatile (in-memory / tmp files)


+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+      WebRTC      +â€”â€”â€”â€”â€”â€”â€”â€”+
|  Browser (Next.js) | â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ OpenAI Realtime (LLM)  |
|  - Mic capture     |                  | - ASR + reasoning      |
|  - Live transcript | â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ - Partial transcripts  |
|  - UI suggestions  |   text/events
+â€”â€”â€”â–²â€“â€“â€“â€“â€“+
â”‚ polling / WS
â”‚
â”‚  JSON LIVE/FNAL
+â€”â€”â€”â”´â€“â€“â€“â€“â€“+
| Next.js API (Node) |
| - /api/realtime    |
| - /api/suggestions |
| - /api/summary     |
| - merge/dedupe     |
+â€“â€“â–²â€“â€“â€“â€“â€“â”¬â€“â€“+
â”‚          â”‚
â”‚Claude    â”‚temp storage
â”‚Sonnet    â”‚(Map/FS)
â–¼          â–¼
+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+
|  Anthropic API     |
|  (Sonnet)          |
+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+



## 1) SÃ©quence â€” Live

1. **Client** ouvre `/meeting/:id` â†’ demande micro.
2. **Client â†” OpenAI Realtime** via **WebRTC**.
3. OpenAI envoie **partial transcripts** (Ã©vÃ©nements texte).
4. **Client** append le texte localement (buffer de 5â€“10 s).
5. Toutes les 5 s, **Client** POST `/api/suggestions` avec:
   - meeting_id
   - transcript_delta (texte des N derniÃ¨res secondes)
6. **API** appelle **Claude Sonnet** (prompt LIVE) â†’ renvoie JSON.
7. **API** fusionne/dÃ©doublonne lâ€™Ã©tat courant en mÃ©moire.
8. **Client** rafraÃ®chit le panneau â€œSuggestionsâ€.

## 2) SÃ©quence â€” Fin de rÃ©union (post)

1. **Client** clique â€œTerminerâ€.
2. **Client** envoie transcript complet Ã  **/api/summary**.
3. **API** appelle **Claude Sonnet** (prompt FINAL).
4. **API** renvoie JSON final (summary / actions / decisions / topics).
5. **Client** affiche `/summary/:id` (avec liens audio/quotes si timestamp).

## 3) Composants & responsabilitÃ©s

- **Client Next.js**
  - Mic â†’ WebRTC â†’ OpenAI Realtime
  - UI Transcript (auto-scroll)
  - UI Suggestions (Ã©ditable, validable)
  - Stockage local minimal (localStorage) si refresh

- **Next.js API**
  - `/api/realtime`: init session (si tu fais aussi passer des tokens cÃ´tÃ© serveur)
  - `/api/suggestions`: 
     - reÃ§oit `transcript_delta`
     - appelle Claude (prompt LIVE)
     - merge/dedupe state
     - renvoie JSON LIVE agrÃ©gÃ©
  - `/api/summary`:
     - reÃ§oit `transcript_full` + liste validÃ©e (optionnel)
     - appelle Claude (prompt FINAL)
     - renvoie JSON FINAL

- **OpenAI Realtime**
  - STT temps rÃ©el + Ã©vÃ©nements texte
  - TrÃ¨s faible latence

- **Claude Sonnet**
  - Extraction sÃ©mantique live
  - SynthÃ¨se finale

## 4) Ã‰tats & erreurs

- **Ã‰tats meeting**: `idle` â†’ `listening` â†’ `analyzing` â†’ `finalizing` â†’ `archived`
- **Erreurs**:
  - WebRTC bloquÃ© â†’ fallback: upload WAV
  - JSON invalide de Claude â†’ re-prompt â€œJSON ONLYâ€ + validation/repair
  - DÃ©connexion Realtime â†’ bouton â€œReprendreâ€

## 5) SÃ©curitÃ© & config

- **.env**
  - `OPENAI_API_KEY=...`
  - `ANTHROPIC_API_KEY=...`
- **Jamais** exposer les clÃ©s au client.
- CORS: restreindre aux origines Vercel.
- Logs: minimaux, pas de donnÃ©es sensibles.

## 6) DÃ©ploiement (Vercel)

- Next.js (App Router)
- Edge pour les routes simples, Node pour les appels Claude (si besoin lib non-edge)
- Variables dâ€™environnement dans Vercel Project Settings
- Feature flags:
  - `USE_WEBSOCKET_SUGGESTIONS=false` (MVP en polling)
  - `LANG_AUTO=true`

## 7) Ã‰volution rapide

- Remplacer polling par **WebSocket** sur `/api/suggestions` (push server â†’ client).
- Ajouter **export Markdown/PDF**.
- Indexer le transcript (pgvector) pour **Q&A** post-meeting.
- IntÃ©grer **Google Calendar** pour proposer des crÃ©neaux de follow-ups.