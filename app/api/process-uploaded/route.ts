import { NextResponse } from 'next/server'
import { prisma } from '@/lib/prisma'
import { requireAuth } from '@/lib/session'
import { estimateTranscriptionTime } from '@/lib/services/whisperService'

export const runtime = 'nodejs'
export const maxDuration = 300 // 5 minutes max sur Vercel Pro

/**
 * Traite un fichier d√©j√† upload√© vers Blob Storage
 * Appel√© apr√®s un upload client-side direct
 */
export async function POST(request: Request) {
  try {
    // Get authenticated user
    let user
    try {
      user = await requireAuth()
    } catch (error) {
      return NextResponse.json(
        { success: false, error: 'Non authentifi√©' },
        { status: 401 }
      )
    }

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        {
          success: false,
          error: 'OpenAI API key not configured',
        },
        { status: 500 }
      )
    }

    const { blobUrl, filename, fileSize } = await request.json()

    if (!blobUrl || !filename) {
      return NextResponse.json(
        { success: false, error: 'Missing blobUrl or filename' },
        { status: 400 }
      )
    }

    console.log(`üì§ Processing uploaded file: ${filename} from ${blobUrl}`)

    const fileSizeMB = fileSize ? fileSize / (1024 * 1024) : 0

    // Cr√©er un meeting dans la base de donn√©es
    const meeting = await prisma.meeting.create({
      data: {
        status: 'processing',
        type: 'upload',
        title: filename,
        transcript: '[]',
        transcriptSegments: '[]',
        topics: '[]',
        decisions: '[]',
        actions: '[]',
        userId: user.id,
        audioPath: blobUrl,
      },
    })

    const meetingId = meeting.id
    const estimatedTime = fileSizeMB > 0 ? estimateTranscriptionTime(fileSizeMB) : 60

    console.log(`‚è±Ô∏è  Estimated transcription time: ${estimatedTime}s`)

    // Sur Vercel, on ne peut pas faire du traitement vraiment asynchrone
    // On a deux options :
    // 1. Traiter synchroniquement (mais risque de timeout apr√®s 300s)
    // 2. Retourner imm√©diatement et faire du polling c√¥t√© client

    // Pour les petits fichiers (< 3 min estim√©), on traite synchroniquement
    // Pour les gros fichiers, on lance en arri√®re-plan et le client poll
    const processSynchronously = estimatedTime < 180 // moins de 3 minutes

    if (processSynchronously) {
      console.log('üì¶ Processing synchronously (estimated time < 3min)')
      try {
        await processAudioFromBlob(meetingId, blobUrl)
        console.log('‚úÖ Synchronous processing completed')
      } catch (error: any) {
        console.error('‚ùå Error during synchronous processing:', error)
        console.error('Error stack:', error.stack)
        // Le meeting reste en status 'processing', le client peut r√©essayer
      }
    } else {
      console.log('üì¶ Processing asynchronously (large file)')
      // D√©marrer en arri√®re-plan (risque de timeout Vercel)
      processAudioFromBlob(meetingId, blobUrl).catch((error) => {
        console.error('‚ùå Error processing audio file:', error)
        console.error('Error stack:', error.stack)

        // Mettre √† jour le meeting avec l'erreur
        prisma.meeting
          .update({
            where: { id: meetingId },
            data: {
              status: 'completed',
            },
          })
          .catch((updateError) => {
            console.error('‚ùå Failed to update meeting after error:', updateError)
          })
      })
    }

    return NextResponse.json({
      success: true,
      meetingId,
      estimatedTime,
      processingMode: processSynchronously ? 'sync' : 'async',
      message: processSynchronously
        ? 'File processed successfully'
        : 'File uploaded successfully. Processing in background...',
    })
  } catch (error: any) {
    console.error('Error processing upload:', error)

    return NextResponse.json(
      { success: false, error: error.message || 'Processing failed' },
      { status: 500 }
    )
  }
}

/**
 * Traite le fichier audio depuis Blob Storage
 */
async function processAudioFromBlob(meetingId: string, blobUrl: string) {
  try {
    console.log(`üéôÔ∏è  Starting transcription from Blob for meeting ${meetingId}`)
    console.log(`üì¶ Blob URL: ${blobUrl}`)

    // T√©l√©charger depuis Blob et transcrire
    console.log(`‚¨áÔ∏è  Downloading from Blob Storage...`)
    const response = await fetch(blobUrl)

    if (!response.ok) {
      throw new Error(`Failed to download from Blob: ${response.status} ${response.statusText}`)
    }

    console.log(`üì• Blob response OK, reading buffer...`)
    const arrayBuffer = await response.arrayBuffer()
    const buffer = Buffer.from(arrayBuffer)
    const sizeMB = buffer.length / (1024 * 1024)

    console.log(`‚úÖ Downloaded ${sizeMB.toFixed(2)} MB from Blob`)

    // Cr√©er un fichier temporaire pour Whisper
    const { writeFile, unlink, mkdir } = await import('fs/promises')
    const { join } = await import('path')
    const { transcribeAudio } = await import('@/lib/services/whisperService')

    const tempDir = join(process.cwd(), 'data', 'temp')

    // Cr√©er le dossier temp s'il n'existe pas
    console.log(`üìÅ Creating temp directory: ${tempDir}`)
    await mkdir(tempDir, { recursive: true })

    const tempFile = join(tempDir, `${meetingId}-temp.audio`)

    console.log(`üíæ Writing to temp file: ${tempFile}`)
    await writeFile(tempFile, buffer)
    console.log(`‚úÖ Temp file written successfully`)

    try {
      // √âtape 1: Transcrire avec Whisper
      console.log(`üé§ Starting Whisper transcription...`)
      const segments = await transcribeAudio(tempFile)

      console.log(`‚úÖ Transcription completed: ${segments.length} segments`)

      // √âtape 2: Stocker les segments
      console.log(`üíæ Saving transcript segments to database...`)
      const transcriptArray = segments.map((s) => s.text)
      await prisma.meeting.update({
        where: { id: meetingId },
        data: {
          transcript: JSON.stringify(transcriptArray),
          transcriptSegments: JSON.stringify(segments),
        },
      })
      console.log(`‚úÖ Transcript saved to database`)

      // √âtape 3: G√©n√©rer le r√©sum√© avec Claude
      const fullTranscript = transcriptArray.join(' ')

      if (fullTranscript.length < 100) {
        console.log('‚ö†Ô∏è Transcript too short, skipping analysis')
        await prisma.meeting.update({
          where: { id: meetingId },
          data: { status: 'completed' },
        })
        return
      }

      console.log(`ü§ñ Analyzing with Claude... (${fullTranscript.length} chars)`)
      const { generateFinalSummary } = await import('@/lib/services/claudeService')

      const summary = await generateFinalSummary(transcriptArray, undefined)
      console.log(`‚úÖ Claude analysis completed`)

      const limitedSuggestions = {
        topics: summary.topics.slice(0, 8),
        decisions: summary.decisions.slice(0, 10),
        actions: summary.actions.slice(0, 15),
      }

      // √âtape 4: Sauvegarder
      await prisma.meeting.update({
        where: { id: meetingId },
        data: {
          topics: JSON.stringify(limitedSuggestions.topics),
          decisions: JSON.stringify(limitedSuggestions.decisions),
          actions: JSON.stringify(limitedSuggestions.actions),
          summary: JSON.stringify(summary),
          status: 'completed',
        },
      })

      console.log(`‚úÖ Processing completed for meeting ${meetingId}`)
    } finally {
      // Nettoyer le fichier temporaire
      await unlink(tempFile).catch(console.error)
    }
  } catch (error) {
    console.error('Error in processAudioFromBlob:', error)

    await prisma.meeting
      .update({
        where: { id: meetingId },
        data: { status: 'completed' },
      })
      .catch(console.error)

    throw error
  }
}
