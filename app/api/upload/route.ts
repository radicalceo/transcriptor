import { NextResponse } from 'next/server'
import { writeFile, unlink } from 'fs/promises'
import { join } from 'path'
import { prisma } from '@/lib/prisma'
import { requireAuth } from '@/lib/session'
import {
  transcribeAudio,
  validateAudioFile,
  estimateTranscriptionTime,
} from '@/lib/services/whisperService'

export async function POST(request: Request) {
  let tempFilePath: string | null = null

  try {
    // Get authenticated user
    let user
    try {
      user = await requireAuth()
    } catch (error) {
      return NextResponse.json(
        { success: false, error: 'Non authentifi√©' },
        { status: 401 }
      )
    }

    // V√©rifier que la cl√© OpenAI est configur√©e
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        {
          success: false,
          error:
            'OpenAI API key not configured. Please add OPENAI_API_KEY to your .env.local file to enable audio file uploads.',
        },
        { status: 500 }
      )
    }

    const formData = await request.formData()
    const file = formData.get('file') as File

    if (!file) {
      return NextResponse.json(
        { success: false, error: 'No file provided' },
        { status: 400 }
      )
    }

    // Validation du fichier
    const fileSizeMB = file.size / (1024 * 1024)
    const validation = validateAudioFile(file.name, fileSizeMB)

    if (!validation.valid) {
      return NextResponse.json(
        { success: false, error: validation.error },
        { status: 400 }
      )
    }

    console.log(`üì§ Uploading file: ${file.name} (${fileSizeMB.toFixed(2)} MB)`)

    // Cr√©er un meeting dans la base de donn√©es
    const meeting = await prisma.meeting.create({
      data: {
        status: 'processing',
        type: 'upload',
        title: file.name,
        transcript: '[]',
        transcriptSegments: '[]',
        topics: '[]',
        decisions: '[]',
        actions: '[]',
        userId: user.id,
      },
    })

    const meetingId = meeting.id

    // Sauvegarder le fichier de mani√®re persistante
    const bytes = await file.arrayBuffer()
    const buffer = Buffer.from(bytes)

    const uploadDir = join(process.cwd(), 'data', 'uploads')
    const fileName = `${meetingId}-${file.name}`
    const filePath = join(uploadDir, fileName)

    await writeFile(filePath, buffer)
    console.log(`üíæ File saved to: ${filePath}`)

    // Mettre √† jour le chemin du fichier dans la DB
    await prisma.meeting.update({
      where: { id: meetingId },
      data: { audioPath: filePath },
    })

    tempFilePath = filePath

    // Estimer le temps de transcription
    const estimatedTime = estimateTranscriptionTime(fileSizeMB)
    console.log(`‚è±Ô∏è  Estimated transcription time: ${estimatedTime}s`)

    // D√©marrer la transcription en arri√®re-plan
    // Note: En production, utilisez un job queue (Bull, etc.)
    processAudioFile(meetingId, filePath).catch((error) => {
      console.error('Error processing audio file:', error)
      prisma.meeting.update({
        where: { id: meetingId },
        data: { status: 'completed' }
      }).catch(console.error)
    })

    return NextResponse.json({
      success: true,
      meetingId,
      estimatedTime,
      message: 'File uploaded successfully. Processing in background...',
    })
  } catch (error: any) {
    console.error('Error uploading file:', error)

    // Nettoyer le fichier temporaire en cas d'erreur
    if (tempFilePath) {
      try {
        await unlink(tempFilePath)
      } catch (unlinkError) {
        console.error('Error deleting temp file:', unlinkError)
      }
    }

    return NextResponse.json(
      { success: false, error: error.message || 'Upload failed' },
      { status: 500 }
    )
  }
}

/**
 * Traite le fichier audio en arri√®re-plan
 */
async function processAudioFile(meetingId: string, filePath: string) {
  try {
    console.log(`üéôÔ∏è  Starting transcription for meeting ${meetingId}`)

    // √âtape 1: Transcrire avec Whisper
    const segments = await transcribeAudio(filePath)

    console.log(`‚úÖ Transcription completed: ${segments.length} segments`)

    // √âtape 2: Stocker les segments avec timestamps
    const transcriptArray = segments.map((s) => s.text)
    await prisma.meeting.update({
      where: { id: meetingId },
      data: {
        transcript: JSON.stringify(transcriptArray),
        transcriptSegments: JSON.stringify(segments),
      },
    })

    // √âtape 3: G√©n√©rer le r√©sum√© complet avec Claude (1 seul appel)
    const fullTranscript = transcriptArray.join(' ')

    if (fullTranscript.length < 100) {
      console.log('‚ö†Ô∏è Transcript too short, skipping analysis')
      await prisma.meeting.update({
        where: { id: meetingId },
        data: { status: 'completed' },
      })
      return
    }

    console.log('ü§ñ Analyzing full transcript with Claude (single call)...')
    const { generateFinalSummary } = await import('@/lib/services/claudeService')

    const summary = await generateFinalSummary(transcriptArray, undefined)

    // Extraire les suggestions du r√©sum√© pour l'affichage live
    const limitedSuggestions = {
      topics: summary.topics.slice(0, 8),
      decisions: summary.decisions.slice(0, 10),
      actions: summary.actions.slice(0, 15),
    }

    // √âtape 4: Sauvegarder les suggestions et le r√©sum√©
    await prisma.meeting.update({
      where: { id: meetingId },
      data: {
        topics: JSON.stringify(limitedSuggestions.topics),
        decisions: JSON.stringify(limitedSuggestions.decisions),
        actions: JSON.stringify(limitedSuggestions.actions),
        summary: JSON.stringify(summary),
        status: 'completed',
      },
    })

    console.log('‚úÖ Analysis completed in single call')
    console.log(`‚úÖ Processing completed for meeting ${meetingId}`)
  } catch (error) {
    console.error('Error in processAudioFile:', error)

    // Marquer comme compl√©t√© m√™me en cas d'erreur
    await prisma.meeting.update({
      where: { id: meetingId },
      data: { status: 'completed' },
    }).catch(console.error)

    throw error
  }
}
