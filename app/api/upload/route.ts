import { NextResponse } from 'next/server'
import { writeFile, unlink } from 'fs/promises'
import { join } from 'path'
import { prisma } from '@/lib/prisma'
import { requireAuth } from '@/lib/session'
import {
  transcribeAudio,
  validateAudioFile,
  estimateTranscriptionTime,
} from '@/lib/services/whisperService'

// Augmenter la limite pour cette route
export const runtime = 'nodejs'
export const maxDuration = 300 // 5 minutes

export async function POST(request: Request) {
  let tempFilePath: string | null = null

  try {
    // Get authenticated user
    let user
    try {
      user = await requireAuth()
    } catch (error) {
      return NextResponse.json(
        { success: false, error: 'Non authentifi√©' },
        { status: 401 }
      )
    }

    // V√©rifier que la cl√© OpenAI est configur√©e
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        {
          success: false,
          error:
            'OpenAI API key not configured. Please add OPENAI_API_KEY to your .env.local file to enable audio file uploads.',
        },
        { status: 500 }
      )
    }

    const formData = await request.formData()
    const file = formData.get('file') as File

    if (!file) {
      return NextResponse.json(
        { success: false, error: 'No file provided' },
        { status: 400 }
      )
    }

    // Validation du fichier
    const fileSizeMB = file.size / (1024 * 1024)
    const validation = validateAudioFile(file.name, fileSizeMB)

    if (!validation.valid) {
      return NextResponse.json(
        { success: false, error: validation.error },
        { status: 400 }
      )
    }

    console.log(`üì§ Uploading file: ${file.name} (${fileSizeMB.toFixed(2)} MB)`)

    // Cr√©er un meeting dans la base de donn√©es
    const meeting = await prisma.meeting.create({
      data: {
        status: 'processing',
        type: 'upload',
        title: file.name,
        transcript: '[]',
        transcriptSegments: '[]',
        topics: '[]',
        decisions: '[]',
        actions: '[]',
        userId: user.id,
      },
    })

    const meetingId = meeting.id

    // Sauvegarder le fichier de mani√®re persistante
    const bytes = await file.arrayBuffer()
    const buffer = Buffer.from(bytes)

    const uploadDir = join(process.cwd(), 'data', 'uploads')
    const fileName = `${meetingId}-${file.name}`
    const filePath = join(uploadDir, fileName)

    await writeFile(filePath, buffer)
    console.log(`üíæ File saved to: ${filePath}`)

    // Mettre √† jour le chemin du fichier dans la DB
    await prisma.meeting.update({
      where: { id: meetingId },
      data: { audioPath: filePath },
    })

    tempFilePath = filePath

    // Estimer le temps de transcription
    const estimatedTime = estimateTranscriptionTime(fileSizeMB)
    console.log(`‚è±Ô∏è  Estimated transcription time: ${estimatedTime}s`)

    // D√©marrer la transcription en arri√®re-plan
    // Note: En production, utilisez un job queue (Bull, etc.)
    processAudioFile(meetingId, filePath).catch((error) => {
      console.error('Error processing audio file:', error)
      prisma.meeting.update({
        where: { id: meetingId },
        data: { status: 'completed' }
      }).catch(console.error)
    })

    return NextResponse.json({
      success: true,
      meetingId,
      estimatedTime,
      message: 'File uploaded successfully. Processing in background...',
    })
  } catch (error: any) {
    console.error('Error uploading file:', error)

    // Nettoyer le fichier temporaire en cas d'erreur
    if (tempFilePath) {
      try {
        await unlink(tempFilePath)
      } catch (unlinkError) {
        console.error('Error deleting temp file:', unlinkError)
      }
    }

    return NextResponse.json(
      { success: false, error: error.message || 'Upload failed' },
      { status: 500 }
    )
  }
}

/**
 * Traite le fichier audio en arri√®re-plan
 */
async function processAudioFile(meetingId: string, filePath: string) {
  try {
    console.log(`üéôÔ∏è  Starting transcription for meeting ${meetingId}`)

    // √âtape 1: Transcrire avec Whisper (avec callback progressif)
    let allSegments: any[] = []

    // Callback pour sauvegarder progressivement
    const onProgress = async (newSegments: any[]) => {
      allSegments.push(...newSegments)

      console.log(`üíæ Saving ${newSegments.length} new segments (total: ${allSegments.length})`)
      const transcriptArray = allSegments.map((s: any) => s.text)

      await prisma.meeting.update({
        where: { id: meetingId },
        data: {
          transcript: JSON.stringify(transcriptArray),
          transcriptSegments: JSON.stringify(allSegments),
        },
      })
    }

    const segments = await transcribeAudio(filePath, 'fr', onProgress)

    console.log(`‚úÖ Transcription completed: ${segments.length} segments`)

    // √âtape 2: Sauvegarder les segments fusionn√©s finaux
    const transcriptArray = segments.map((s) => s.text)
    await prisma.meeting.update({
      where: { id: meetingId },
      data: {
        transcript: JSON.stringify(transcriptArray),
        transcriptSegments: JSON.stringify(segments),
      },
    })

    // √âtape 3: G√©n√©rer le r√©sum√© complet avec Claude (1 seul appel)
    const fullTranscript = transcriptArray.join(' ')

    // Tenter de g√©n√©rer le r√©sum√© avec Claude (m√™me pour les courts extraits)
    let summary = null
    try {
      console.log('ü§ñ Analyzing full transcript with Claude (single call)...')
      const { generateFinalSummary } = await import('@/lib/services/claudeService')

      summary = await generateFinalSummary(transcriptArray, undefined)
      console.log('‚úÖ Analysis completed in single call')
    } catch (claudeError: any) {
      console.error('‚ö†Ô∏è Claude analysis failed:', claudeError.message)
      console.error('Transcript will be saved without summary')
    }

    // √âtape 4: Sauvegarder les suggestions et le r√©sum√© (avec ou sans r√©sum√©)
    if (summary) {
      const limitedSuggestions = {
        topics: summary.topics.slice(0, 8),
        decisions: summary.decisions.slice(0, 10),
        actions: summary.actions.slice(0, 15),
      }

      await prisma.meeting.update({
        where: { id: meetingId },
        data: {
          topics: JSON.stringify(limitedSuggestions.topics),
          decisions: JSON.stringify(limitedSuggestions.decisions),
          actions: JSON.stringify(limitedSuggestions.actions),
          summary: JSON.stringify(summary),
          status: 'completed',
        },
      })
    } else {
      // Juste marquer comme compl√©t√© sans r√©sum√©
      await prisma.meeting.update({
        where: { id: meetingId },
        data: { status: 'completed' },
      })
    }

    console.log(`‚úÖ Processing completed for meeting ${meetingId}`)

    // Envoyer l'email de notification
    try {
      const meetingWithUser = await prisma.meeting.findUnique({
        where: { id: meetingId },
        include: { user: true },
      })

      if (meetingWithUser?.user) {
        const { sendTranscriptionCompleteEmail } = await import('@/lib/email')
        await sendTranscriptionCompleteEmail({
          userEmail: meetingWithUser.user.email,
          userName: meetingWithUser.user.name,
          meetingId: meetingId,
          meetingTitle: meetingWithUser.title || 'Enregistrement audio',
        })
      }
    } catch (emailError) {
      console.error('‚ö†Ô∏è Failed to send completion email:', emailError)
      // Ne pas bloquer si l'email √©choue
    }
  } catch (error) {
    console.error('Error in processAudioFile:', error)

    // Marquer comme compl√©t√© m√™me en cas d'erreur
    await prisma.meeting.update({
      where: { id: meetingId },
      data: { status: 'completed' },
    }).catch(console.error)

    throw error
  }
}
